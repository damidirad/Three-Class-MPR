{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the MovieLens-1M Dataset\n",
        "\n",
        "This notebook outlines the preprocessing steps used to create a synthetic [MovieLens-1M dataset (2003)](https://grouplens.org/datasets/movielens/1m/) with three gender classes (M/F/NB) as the sensitive attribute. An iterative k-core filter is applied to the interaction data to remove sparse users/items and keep a dense, well-supported subset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Configuration\n",
        "\n",
        "The configuration is set so that the non-binary class replaces 10% of the original user population. In addition, a 10-core filtering is used by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "DATA_DIR = Path(os.getenv('PROJECT_ROOT', Path.cwd()))\n",
        "\n",
        "NON_BINARY_FRAC = 0.1\n",
        "RANDOM_SEED = 42\n",
        "K_CORE_FILTER = 10\n",
        "\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load User Data\n",
        "\n",
        "User data is loaded and reduced to user IDs and gender labels, which serve as the sensitive attribute; all other columns are discarded. IDs are shifted to 0-based indexing to match the preprocessing convention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "users_df = pd.read_csv(\n",
        "    filepath_or_buffer='users.dat',\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    usecols=[0, 1],\n",
        "    names=['user_id', 'gender']\n",
        ")\n",
        "\n",
        "users_df['user_id'] = users_df['user_id'] - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Non-Binary Gender Class\n",
        "\n",
        "A synthetic non-binary attribute is created by randomly sampling 10% of users from the existing male and female populations while preserving their original ratio. Gender labels are displayed before and after the transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "INITIAL GENDER DISTRIBUTION\n",
            "============================================================\n",
            "Male:   4331 (71.7%)\n",
            "Female: 1709 (28.3%) \n",
            "\n",
            "============================================================\n",
            "ASSIGNING NON-BINARY GENDERS\n",
            "============================================================\n",
            "Sampling 10% of users to be non-binary.\n",
            "Sampling respects the existing M/F ratio (2.534):\n",
            "  - 434 from male users\n",
            "  - 170 from female users \n",
            "\n",
            "============================================================\n",
            "RESULTING GENDER DISTRIBUTION\n",
            "============================================================\n",
            "Men:        3897 (64.5%)\n",
            "Women:      1539 (25.5%)\n",
            "Non-binary:  604 (10.0%) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "male_count = users_df[users_df['gender'] == 'M'].shape[0]\n",
        "female_count = users_df[users_df['gender'] == 'F'].shape[0]\n",
        "total_users = male_count + female_count\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"INITIAL GENDER DISTRIBUTION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Male:':<7} {male_count:<3} ({male_count/total_users*100:>4.1f}%)\")\n",
        "print(f\"{'Female:':<7} {female_count:<3} ({female_count/total_users*100:>4.1f}%) \\n\")\n",
        "\n",
        "num_non_binary = int(total_users * NON_BINARY_FRAC)\n",
        "\n",
        "# Sample users to become non-binary (respecting existing gender ratio)\n",
        "gender_counts = users_df['gender'].value_counts()\n",
        "ratio_m_f = gender_counts['M'] / gender_counts['F']\n",
        "num_nb_from_female = int(num_non_binary / (1 + ratio_m_f))\n",
        "num_nb_from_male = num_non_binary - num_nb_from_female\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ASSIGNING NON-BINARY GENDERS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Sampling {NON_BINARY_FRAC*100:.0f}% of users to be non-binary.\")\n",
        "print(f\"Sampling respects the existing M/F ratio ({ratio_m_f:.3f}):\")\n",
        "print(f\"  - {num_nb_from_male} from male users\")\n",
        "print(f\"  - {num_nb_from_female} from female users \\n\")\n",
        "\n",
        "male_indices = users_df[users_df['gender'] == 'M'].sample(\n",
        "    n=num_nb_from_male, random_state=RANDOM_SEED\n",
        ").index\n",
        "female_indices = users_df[users_df['gender'] == 'F'].sample(\n",
        "    n=num_nb_from_female, random_state=RANDOM_SEED\n",
        ").index\n",
        "\n",
        "# Combine and assign non-binary\n",
        "nb_indices = male_indices.union(female_indices)\n",
        "users_df.loc[nb_indices, 'gender'] = 'NB'\n",
        "\n",
        "male_count = users_df[users_df['gender'] == 'M'].shape[0]\n",
        "female_count = users_df[users_df['gender'] == 'F'].shape[0]\n",
        "nb_count = users_df[users_df['gender'] == 'NB'].shape[0]\n",
        "\n",
        "assert total_users == male_count + female_count + nb_count, (\n",
        "    f\"Population mismatch after assigning non-binary genders. \"\n",
        "    f\"Before: {total_users}, \"\n",
        "    f\"After: {male_count + female_count + nb_count}\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RESULTING GENDER DISTRIBUTION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Men:':<11} {male_count:<3} ({male_count/total_users*100:>4.1f}%)\")\n",
        "print(f\"{'Women:':<11} {female_count:<3} ({female_count/total_users*100:>4.1f}%)\")\n",
        "print(f\"{'Non-binary:':<12} {nb_count:<3} ({nb_count/total_users*100:>4.1f}%) \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Interaction Data\n",
        "\n",
        "User–item interaction data is loaded and IDs are shifted to 0-based indexing. Ratings on the 1–5 scale are binarized (rating > 4 as positive), after which the original rating values are discarded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "items_df = pd.read_csv(\n",
        "    filepath_or_buffer='ratings.dat',\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    usecols=[0, 1, 2],  # Skip timestamp\n",
        "    names=['user_id', 'item_id', 'rating']\n",
        ")\n",
        "\n",
        "items_df['user_id'] = items_df['user_id'] - 1\n",
        "items_df['item_id'] = items_df['item_id'] - 1\n",
        "\n",
        "items_df['label'] = (items_df['rating'] > 4).astype(int)\n",
        "items_df = items_df.drop(columns=['rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Core Filtering\n",
        "\n",
        "An iterative k-core filter removes users and items with fewer than k=10 interactions. The process repeats until no more entities fall below the threshold, ensuring a dense dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "BEFORE ITERATIVE K-CORE FILTERING\n",
            "============================================================\n",
            "Total interactions: 1,000,209\n",
            "Min interactions per user: 20\n",
            "Min interactions per item: 1 \n",
            "\n",
            "============================================================\n",
            "AFTER ITERATIVE K-CORE FILTERING\n",
            "============================================================\n",
            "Total interactions: 998,539\n",
            "Min interactions per user: 17\n",
            "Min interactions per item: 10 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"BEFORE ITERATIVE K-CORE FILTERING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total interactions: {len(items_df):,}\")\n",
        "print(f\"Min interactions per user: {items_df['user_id'].value_counts().min()}\")\n",
        "print(f\"Min interactions per item: {items_df['item_id'].value_counts().min()} \\n\")\n",
        "\n",
        "users_before = set(items_df[\"user_id\"].unique())\n",
        "\n",
        "def iterative_filter(df, k_user=10, k_item=10):\n",
        "    prev_shape = None\n",
        "    current_df = df.copy()\n",
        "\n",
        "    while prev_shape != current_df.shape:\n",
        "        prev_shape = current_df.shape\n",
        "\n",
        "        # Filter users\n",
        "        user_counts = current_df['user_id'].value_counts()\n",
        "        current_df = current_df[current_df['user_id'].map(user_counts) >= k_user]\n",
        "\n",
        "        # Filter items\n",
        "        item_counts = current_df['item_id'].value_counts()\n",
        "        current_df = current_df[current_df['item_id'].map(item_counts) >= k_item]\n",
        "    \n",
        "    return current_df\n",
        "\n",
        "items_df = iterative_filter(items_df, k_user=K_CORE_FILTER, k_item=K_CORE_FILTER)\n",
        "\n",
        "users_after = set(items_df[\"user_id\"].unique())\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"AFTER ITERATIVE K-CORE FILTERING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total interactions: {len(items_df):,}\")\n",
        "print(f\"Min interactions per user: {items_df['user_id'].value_counts().min()}\")\n",
        "print(f\"Min interactions per item: {items_df['item_id'].value_counts().min()} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update Users DataFrame\n",
        "\n",
        "User data is synchronized with the filtered interaction data by removing users that were eliminated during k-core filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No users removed during filtering. Proceeding without updating users dataframe. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "removed_users = users_before.difference(users_after)\n",
        "\n",
        "if len(removed_users) > 0:\n",
        "    print(f\"{len(removed_users)} users removed during filtering. Updating users dataframe... \\n\")\n",
        "    valid_user_ids = items_df['user_id'].unique()\n",
        "    users_df = users_df[users_df['user_id'].isin(valid_user_ids)].reset_index(drop=True)\n",
        "elif len(removed_users) == 0:\n",
        "    print(\"No users removed during filtering. Proceeding without updating users dataframe. \\n\")\n",
        "else:\n",
        "    raise ValueError(\"Unexpected condition: more users after filtering than before. \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train/Val/Test Split\n",
        "\n",
        "Interactions are split per user (80% train, 10% validation, 10% test) so that users are represented across splits. This reduces distribution shifts between splits and supports a more realistic evaluation setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATASET SPLITS\n",
            "============================================================\n",
            "Train size: 796,389\n",
            "Valid size:  97,199\n",
            "Test size:  104,951\n",
            "Total size: 998,539 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def split_per_user(df, train_frac=0.8, val_frac=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    Splitting items per user by using groupby and apply.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with user_id column\n",
        "        train_frac: Fraction for training\n",
        "        val_frac: Fraction for validation\n",
        "        random_state: Random seed\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df, test_df\n",
        "    \"\"\"\n",
        "    def split_user_data(user_items):\n",
        "        \"\"\"\n",
        "        Split a single user's interactions into train/val/test sets.\n",
        "        \"\"\"\n",
        "        user_id = user_items.name\n",
        "        user_items = user_items.copy()\n",
        "        user_items['user_id'] = user_id\n",
        "\n",
        "        user_items = user_items.sample(frac=1, random_state=random_state) # Shuffle items\n",
        "        num_items = len(user_items)\n",
        "\n",
        "        num_train = int(train_frac * num_items)\n",
        "        num_val = int(val_frac * num_items)\n",
        "\n",
        "        split_labels = ['train'] * num_train + ['val'] * num_val + ['test'] * (num_items - num_train - num_val)\n",
        "        user_items['split'] = split_labels\n",
        "\n",
        "        return user_items\n",
        "\n",
        "    # Apply splitting to each user's items\n",
        "    df_with_splits = df.groupby('user_id', group_keys=False).apply(split_user_data)\n",
        "    df_with_splits = df_with_splits[['user_id', 'item_id', 'label', 'split']] # Reorder columns\n",
        "\n",
        "    train_df = df_with_splits[df_with_splits['split'] == 'train'].drop(columns=['split'])\n",
        "    valid_df = df_with_splits[df_with_splits['split'] == 'val'].drop(columns=['split'])\n",
        "    test_df = df_with_splits[df_with_splits['split'] == 'test'].drop(columns=['split'])\n",
        "\n",
        "    return (\n",
        "        train_df.reset_index(drop=True),\n",
        "        valid_df.reset_index(drop=True),\n",
        "        test_df.reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "train_df, valid_df, test_df = split_per_user(items_df, random_state=RANDOM_SEED)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET SPLITS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Train size:':<11} {len(train_df):>5,}\")\n",
        "print(f\"{'Valid size:':<12} {len(valid_df):>5,}\")\n",
        "print(f\"{'Test size:':<11} {len(test_df):>5,}\")\n",
        "print(f\"{'Total size:':<11} {len(train_df) + len(valid_df) + len(test_df):>5,} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Save Output Files\n",
        "\n",
        "Final dataset statistics are displayed, gender labels are mapped to integers (M=0, F=1, NB=2), and all processed files are saved to CSV format, including both ordered and randomized versions of the sensitive attribute data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FINAL DATASET SUMMARY\n",
            "============================================================\n",
            "Total users: 6040\n",
            "Total items: 3260\n",
            "Total interactions: 998,539\n",
            "\n",
            "Final gender distribution:\n",
            " - Male:       3897 (64.5%)\n",
            " - Female:     1539 (25.5%)\n",
            " - Non-binary:  604 (10.0%) \n",
            "\n",
            "Mapping gender labels to integers...\n",
            "\n",
            "Saving processed files to: Three-Class-MPR/datasets/ml-1m-synthetic \n",
            "\n",
            "✓ All files saved successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"FINAL DATASET SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total users: {len(users_df)}\")\n",
        "print(f\"Total items: {items_df['item_id'].nunique()}\")\n",
        "print(f\"Total interactions: {len(train_df) + len(valid_df) + len(test_df):,}\")\n",
        "\n",
        "male_final = (users_df['gender'] == 'M').sum()\n",
        "female_final = (users_df['gender'] == 'F').sum()\n",
        "nb_final = (users_df['gender'] == 'NB').sum()\n",
        "\n",
        "print(f\"\\nFinal gender distribution:\")\n",
        "print(f\" - {'Male:':<11} {male_final:>4} ({male_final/len(users_df)*100:.1f}%)\")\n",
        "print(f\" - {'Female:':<11} {female_final:>4} ({female_final/len(users_df)*100:.1f}%)\")\n",
        "print(f\" - {'Non-binary:':<11} {nb_final:>4} ({nb_final/len(users_df)*100:.1f}%) \\n\")\n",
        "\n",
        "print(\"Mapping gender labels to integers...\")\n",
        "gender_mapping = {'M': 0, 'F': 1, 'NB': 2}\n",
        "users_df['gender'] = users_df['gender'].map(gender_mapping)\n",
        "\n",
        "# Randomized sensitive attribute dataset\n",
        "users_random = users_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nSaving processed files to: {DATA_DIR.parent.parent.name}/{DATA_DIR.parent.name}/{DATA_DIR.name} \\n\")\n",
        "\n",
        "users_df.to_csv('sensitive_attribute.csv', index=False)\n",
        "users_random.to_csv('sensitive_attribute_random.csv', index=False)\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "valid_df.to_csv('valid.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\n",
        "print(\"✓ All files saved successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fact_py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
