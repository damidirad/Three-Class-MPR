{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCXZN1Wu8OIs",
        "outputId": "60f4d05d-0519-4609-8b86-79ff4ec640ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "INITIAL GENDER DISTRIBUTION\n",
            "============================================================\n",
            "Male: 4331\n",
            "Female: 1709\n",
            "Total: 6040\n",
            "Ratio (M/F): 2.534 \n",
            "\n",
            "Sampling 10% of users to be non-binary.\n",
            "Sampling respects the existing M/F ratio:\n",
            "  - 434 from male users\n",
            "  - 170 from female users \n",
            "\n",
            "============================================================\n",
            "AFTER NON-BINARY SAMPLING\n",
            "============================================================\n",
            "Men: 3897 (64.5%)\n",
            "Women: 1539 (25.5%)\n",
            "Non-binary: 604 (10.0%) \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Dataset splits:\n",
            "Train size: 797,758\n",
            "Val size: 97,383\n",
            "Test size: 105,068\n",
            "\n",
            "✓ All files saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "PROJECT_ROOT = Path(\n",
        "    os.getenv(\"PROJECT_ROOT\", Path.cwd())\n",
        ")\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"datasets\" / \"ml-1m-synthetic\"\n",
        "\n",
        "NON_BINARY_FRAC = 0.1\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESS USERS DATA\n",
        "# ============================================================================\n",
        "\n",
        "# Read only needed columns\n",
        "users_df = pd.read_csv(\n",
        "    DATA_DIR / 'users.dat',\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    usecols=[0, 1],  # Only user_id and gender\n",
        "    names=['user_id', 'gender']\n",
        ")\n",
        "\n",
        "# Adjust user_id indexing\n",
        "users_df['user_id'] = users_df['user_id'] - 1\n",
        "\n",
        "# Show initial statistics\n",
        "male_count = users_df[users_df['gender'] == 'M'].shape[0]\n",
        "female_count = users_df[users_df['gender'] == 'F'].shape[0]\n",
        "total = male_count + female_count\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"INITIAL GENDER DISTRIBUTION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Male: {male_count}\")\n",
        "print(f\"Female: {female_count}\")\n",
        "print(f\"Total: {total}\")\n",
        "print(f\"Ratio (M/F): {male_count/female_count:.3f} \\n\")\n",
        "\n",
        "# Create non-binary category more efficiently\n",
        "n_users = len(users_df)\n",
        "n_non_binary = int(n_users * NON_BINARY_FRAC)\n",
        "\n",
        "# Sample users to become non-binary (respecting existing gender ratio)\n",
        "gender_counts = users_df['gender'].value_counts()\n",
        "ratio_m_f = gender_counts['M'] / gender_counts['F']\n",
        "\n",
        "n_nb_from_female = int(n_non_binary / (1 + ratio_m_f))\n",
        "n_nb_from_male = n_non_binary - n_nb_from_female\n",
        "\n",
        "print(f\"Sampling {NON_BINARY_FRAC*100:.0f}% of users to be non-binary.\")\n",
        "print(f\"Sampling respects the existing M/F ratio:\")\n",
        "print(f\"  - {n_nb_from_male} from male users\")\n",
        "print(f\"  - {n_nb_from_female} from female users \\n\")\n",
        "\n",
        "# Sample indices directly\n",
        "male_indices = users_df[users_df['gender'] == 'M'].sample(\n",
        "    n=n_nb_from_male, random_state=RANDOM_SEED\n",
        ").index\n",
        "female_indices = users_df[users_df['gender'] == 'F'].sample(\n",
        "    n=n_nb_from_female, random_state=RANDOM_SEED\n",
        ").index\n",
        "\n",
        "# Combine and assign non-binary\n",
        "nb_indices = male_indices.union(female_indices)\n",
        "users_df.loc[nb_indices, 'gender'] = 'NB'\n",
        "\n",
        "# Calculate new statistics\n",
        "male_count_after = users_df[users_df['gender'] == 'M'].shape[0]\n",
        "female_count_after = users_df[users_df['gender'] == 'F'].shape[0]\n",
        "nb_count = users_df[users_df['gender'] == 'NB'].shape[0]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"AFTER NON-BINARY SAMPLING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Men: {male_count_after} ({male_count_after/total*100:.1f}%)\")\n",
        "print(f\"Women: {female_count_after} ({female_count_after/total*100:.1f}%)\")\n",
        "print(f\"Non-binary: {nb_count} ({nb_count/total*100:.1f}%) \\n\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Map genders to integers\n",
        "gender_mapping = {'M': 0, 'F': 1, 'NB': 2}\n",
        "users_df['gender'] = users_df['gender'].map(gender_mapping)\n",
        "\n",
        "# Save both ordered and randomized versions\n",
        "users_df.to_csv(DATA_DIR / 'sensitive_attribute.csv', index=False)\n",
        "\n",
        "users_random = users_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "users_random.to_csv(DATA_DIR / 'sensitive_attribute_random.csv', index=False)\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESS RATINGS DATA\n",
        "# ============================================================================\n",
        "\n",
        "items_df = pd.read_csv(\n",
        "    DATA_DIR / 'ratings.dat',\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    usecols=[0, 1, 2],  # Skip timestamp\n",
        "    names=['user_id', 'item_id', 'rating']\n",
        ")\n",
        "\n",
        "# Process items\n",
        "items_df['user_id'] = items_df['user_id'] - 1\n",
        "items_df['item_id'] = items_df['item_id'] - 1\n",
        "items_df['label'] = (items_df['rating'] > 4).astype(int)\n",
        "items_df = items_df.drop(columns=['rating'])\n",
        "\n",
        "# ============================================================================\n",
        "# SPLIT DATA PER USER (OPTIMIZED)\n",
        "# ============================================================================\n",
        "\n",
        "def split_per_user_optimized(df, train_frac=0.8, val_frac=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    Optimized per-user splitting using groupby and apply.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with user_id column\n",
        "        train_frac: Fraction for training\n",
        "        val_frac: Fraction for validation\n",
        "        random_state: Random seed\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df, test_df\n",
        "    \"\"\"\n",
        "    def split_user_data(group):\n",
        "        # Shuffle group\n",
        "        user_id = group.name\n",
        "        group = group.sample(frac=1, random_state=random_state)\n",
        "        n = len(group)\n",
        "\n",
        "        n_train = int(train_frac * n)\n",
        "        n_val = int(val_frac * n)\n",
        "\n",
        "        # Add split indicator\n",
        "        split = ['train'] * n_train + ['val'] * n_val + ['test'] * (n - n_train - n_val)\n",
        "        group['split'] = split\n",
        "        group['user_id'] = user_id\n",
        "\n",
        "        return group\n",
        "\n",
        "    # Apply splitting to each user group\n",
        "    df_with_splits = df.groupby('user_id', group_keys=False).apply(split_user_data, include_groups=False)\n",
        "    df_with_splits = df_with_splits[['user_id', 'item_id', 'label', 'split']]\n",
        "\n",
        "    # Split into separate dataframes\n",
        "    train_df = df_with_splits[df_with_splits['split'] == 'train'].drop(columns=['split'])\n",
        "    val_df = df_with_splits[df_with_splits['split'] == 'val'].drop(columns=['split'])\n",
        "    test_df = df_with_splits[df_with_splits['split'] == 'test'].drop(columns=['split'])\n",
        "\n",
        "    return (\n",
        "        train_df.reset_index(drop=True),\n",
        "        val_df.reset_index(drop=True),\n",
        "        test_df.reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# Perform split\n",
        "df_train, df_val, df_test = split_per_user_optimized(items_df, random_state=RANDOM_SEED)\n",
        "\n",
        "print(f\"\\nDataset splits:\")\n",
        "print(f\"Train size: {len(df_train):,}\")\n",
        "print(f\"Val size: {len(df_val):,}\")\n",
        "print(f\"Test size: {len(df_test):,}\\n\")\n",
        "\n",
        "# Save splits\n",
        "df_train.to_csv(DATA_DIR / 'train.csv', index=False)\n",
        "df_val.to_csv(DATA_DIR / 'valid.csv', index=False)\n",
        "df_test.to_csv(DATA_DIR / 'test.csv', index=False)\n",
        "\n",
        "print(\"✓ All files saved successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
